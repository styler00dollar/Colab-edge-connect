{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-edge-connect.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEkV-m5FEJoM",
        "colab_type": "text"
      },
      "source": [
        "# edge-connect with differentiable augmentation\n",
        "edge-connect: [knazeri/edge-connect](https://github.com/knazeri/edge-connect)\n",
        "\n",
        "Yukariins fork: [Yukariin/edge-connect](https://github.com/Yukariin/edge-connect)\n",
        "\n",
        "Differentiable Augmentation: [mit-han-lab/data-efficient-gans](https://github.com/mit-han-lab/data-efficient-gans)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPLdOlecCkFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check gpu\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL5SvTn5BdBV",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install\n",
        "!git clone https://github.com/knazeri/edge-connect.git\n",
        "%cd edge-connect\n",
        "!pip install -r requirements.txt\n",
        "#!bash ./scripts/download_model.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsHuihTpErN4",
        "colab_type": "text"
      },
      "source": [
        "# Test with pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW0V5LkRB4ej",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Download models\n",
        "%cd /content/edge-connect\n",
        "!pip install gdown\n",
        "!mkdir checkpoint_places\n",
        "%cd checkpoint_places\n",
        "# /checkpoints broken\n",
        "# places\n",
        "!gdown --id 1gesVuuYMtlWSQRR2JE5eO0QZHskYRfqv\n",
        "!gdown --id 1_oYnmK7kppXqka9UUsHrZB4gWE4ouSgT\n",
        "!gdown --id 1M-r_ds4VZJnUqViDMofd4-Fy8-q2aeKJ\n",
        "!gdown --id 1G8lXquU3eREfs8KorFpFC8N4YmTQRksF\n",
        "%cd ..\n",
        "!mkdir checkpoint_celeba\n",
        "%cd checkpoint_celeba\n",
        "!gdown --id 1wy0pEaXTqmya2yeLwWFmTBf4ICexCdce\n",
        "!gdown --id 1hqZRjnqZBGnSTtGJRHXEvvdGVICUGa7u\n",
        "!gdown --id 17FemN4FAKpS5-8Dos582IrOiSCZNDOAO\n",
        "!gdown --id 15mH1ZHMf83q3woBHFELr_TptSRGc5g5j\n",
        "%cd ..\n",
        "!mkdir checkpoint_street\n",
        "%cd checkpoint_street\n",
        "!gdown --id 1ORF2uN4lB3F6YndPm1ny8VIDrsWQBwUS\n",
        "!gdown --id 1EwHK8YjcpO-X3xhmeo2dtqGvtY5vOMMj\n",
        "!gdown --id 1AWxB8AwTOrlOmAUho3IQQlmawtp3y8gZ\n",
        "!gdown --id 12Ua8oQwk0iLdYgrb08bqBhfyiBIumQEK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM4GOSz3CzJl",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title dummy config\n",
        "%%writefile /content/edge-connect/config.yml\n",
        "MODE: 1             # 1: train, 2: test, 3: eval\n",
        "MODEL: 1            # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model\n",
        "MASK: 3             # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)\n",
        "EDGE: 1             # 1: canny, 2: external\n",
        "NMS: 1              # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny\n",
        "SEED: 10            # random seed\n",
        "GPU: [0]            # list of gpu ids\n",
        "DEBUG: 0            # turns on debugging mode\n",
        "VERBOSE: 0          # turns on verbose mode in the output console\n",
        "\n",
        "TRAIN_FLIST: ./datasets/places2_train.flist\n",
        "VAL_FLIST: ./datasets/places2_val.flist\n",
        "TEST_FLIST: ./datasets/places2_test.flist\n",
        "\n",
        "TRAIN_EDGE_FLIST: ./datasets/places2_edges_train.flist\n",
        "VAL_EDGE_FLIST: ./datasets/places2_edges_val.flist\n",
        "TEST_EDGE_FLIST: ./datasets/places2_edges_test.flist\n",
        "\n",
        "TRAIN_MASK_FLIST: ./datasets/masks_train.flist\n",
        "VAL_MASK_FLIST: ./datasets/masks_val.flist\n",
        "TEST_MASK_FLIST: ./datasets/masks_test.flist\n",
        "\n",
        "LR: 0.0001                    # learning rate\n",
        "D2G_LR: 0.1                   # discriminator/generator learning rate ratio\n",
        "BETA1: 0.0                    # adam optimizer beta1\n",
        "BETA2: 0.9                    # adam optimizer beta2\n",
        "BATCH_SIZE: 8                 # input batch size for training\n",
        "INPUT_SIZE: 256               # input image size for training 0 for original size\n",
        "SIGMA: 2                      # standard deviation of the Gaussian filter used in Canny edge detector (0: random, -1: no edge)\n",
        "MAX_ITERS: 2e6                # maximum number of iterations to train the model\n",
        "\n",
        "EDGE_THRESHOLD: 0.5           # edge detection threshold\n",
        "L1_LOSS_WEIGHT: 1             # l1 loss weight\n",
        "FM_LOSS_WEIGHT: 10            # feature-matching loss weight\n",
        "STYLE_LOSS_WEIGHT: 250        # style loss weight\n",
        "CONTENT_LOSS_WEIGHT: 0.1      # perceptual loss weight\n",
        "INPAINT_ADV_LOSS_WEIGHT: 0.1  # adversarial loss weight\n",
        "\n",
        "GAN_LOSS: nsgan               # nsgan | lsgan | hinge\n",
        "GAN_POOL_SIZE: 0              # fake images pool size\n",
        "\n",
        "SAVE_INTERVAL: 1000           # how many iterations to wait before saving model (0: never)\n",
        "SAMPLE_INTERVAL: 1000         # how many iterations to wait before sampling (0: never)\n",
        "SAMPLE_SIZE: 12               # number of images to sample\n",
        "EVAL_INTERVAL: 0              # how many iterations to wait before model evaluation (0: never)\n",
        "LOG_INTERVAL: 10              # how many iterations to wait before logging training status (0: never)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29t2_4dwGVPM",
        "colab_type": "text"
      },
      "source": [
        "Currently default paths are ```/content/image.png``` and ```/content/mask.png```. Currently it's not supported that you change paths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgnGR9NAUqJg",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Image and mask need to be dividable by 4, this code does fix wrong images \n",
        "import cv2\n",
        "import numpy\n",
        "path_inpainting = '/content/image.png' #@param {type:\"string\"}\n",
        "path_mask = '/content/mask.png' #@param {type:\"string\"}\n",
        "image=cv2.imread(path_mask)\n",
        "image_size0 = numpy.floor(image.shape[0]/4)\n",
        "image_size1 = numpy.floor(image.shape[1]/4)\n",
        "image=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "ret,image=cv2.threshold(image,254,255,cv2.THRESH_BINARY)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_mask, image)\n",
        "\n",
        "image=cv2.imread(path_inpainting)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_inpainting, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4WHBATxfdl-",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title print shape\n",
        "import cv2\n",
        "image = cv2.imread(path_inpainting)\n",
        "print(image.shape)\n",
        "image = cv2.imread(path_mask)\n",
        "print(image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuvHUtBwBri8",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Test Inpainting (result will be ```image.png```, the same filename you used as input)\n",
        "%cd /content/edge-connect\n",
        "!python test.py \\\n",
        "  --model 3 \\\n",
        "  --checkpoints /content/edge-connect/checkpoint_places \\\n",
        "  --input /content/image.png \\\n",
        "  --mask /content/mask.png \\\n",
        "  --output /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ard4kblETXdL",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hpN03bmG3Ja",
        "colab_type": "text"
      },
      "source": [
        "Interesting stuff:\n",
        "- New pytorch versions won't work. Pytorch 1.0 makes problems. Pytorch 1.1 seems to work fine.\n",
        "- The ```.tflist``` simply lists filepaths for images.\n",
        "- It supports blocks as inpainting method, but random/custom masks need to be manually downloaded and input with a ```.tflist``` as well. Two example datasets are linked in the original github.\n",
        "- [Model 4 is not recommended](https://github.com/knazeri/edge-connect/issues/144). You should probably use model 3.\n",
        "- [Resuming and using a model as pretrained is being done by simply starting training while the models are in the specified checkpoint path.](https://github.com/knazeri/edge-connect/issues/54)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Wh1jlgm0mxJ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title update mask generator in utils.py ([Yukariin /edge-connect](https://github.com/Yukariin/edge-connect/blob/master/src/utils.py))\n",
        "%%writefile /content/edge-connect/src/utils.py\n",
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "def create_dir(dir):\n",
        "    if not os.path.exists(dir):\n",
        "        os.makedirs(dir)\n",
        "\n",
        "\n",
        "def create_mask(width, height, mask_width, mask_height, x=None, y=None,\n",
        "                min_stroke=1, max_stroke=4,\n",
        "                min_vertex=1, max_vertex=12,\n",
        "                min_length_divisor=10, max_length_divisor=2,\n",
        "                min_brush_width_divisor=30, max_brush_width_divisor=8):\n",
        "    mask = np.zeros((height, width))\n",
        "\n",
        "    min_length = height // min_length_divisor\n",
        "    max_length = height // max_length_divisor\n",
        "    min_brush_width = height // min_brush_width_divisor\n",
        "    max_brush_width = height // max_brush_width_divisor\n",
        "    max_angle = 2*np.pi\n",
        "    num_stroke = np.random.randint(min_stroke, max_stroke+1)\n",
        "\n",
        "    for _ in range(num_stroke):\n",
        "        num_vertex = np.random.randint(min_vertex, max_vertex+1)\n",
        "        brush_width = np.random.randint(min_brush_width, max_brush_width+1)\n",
        "        start_x = np.random.randint(width)\n",
        "        start_y = np.random.randint(height)\n",
        "\n",
        "        for i in range(num_vertex):\n",
        "            angle = np.random.uniform(max_angle)\n",
        "            length = np.random.randint(min_length, max_length+1)\n",
        "            end_x = (start_x + length * np.sin(angle)).astype(np.int32)\n",
        "            end_y = (start_y + length * np.cos(angle)).astype(np.int32)\n",
        "\n",
        "            cv2.line(mask, (start_y, start_x), (end_y, end_x), 1., brush_width)\n",
        "\n",
        "            start_x, start_y = end_x, end_y\n",
        "\n",
        "    if np.random.random() < 0.5:\n",
        "        mask = np.fliplr(mask)\n",
        "    if np.random.random() < 0.5:\n",
        "        mask = np.flipud(mask)\n",
        "\n",
        "    return mask\n",
        "\n",
        "\n",
        "def stitch_images(inputs, *outputs, img_per_row=2):\n",
        "    gap = 5\n",
        "    columns = len(outputs) + 1\n",
        "\n",
        "    width, height = inputs[0][:, :, 0].shape\n",
        "    img = Image.new('RGB', (width * img_per_row * columns + gap * (img_per_row - 1), height * int(len(inputs) / img_per_row)))\n",
        "    images = [inputs, *outputs]\n",
        "\n",
        "    for ix in range(len(inputs)):\n",
        "        xoffset = int(ix % img_per_row) * width * columns + int(ix % img_per_row) * gap\n",
        "        yoffset = int(ix / img_per_row) * height\n",
        "\n",
        "        for cat in range(len(images)):\n",
        "            im = np.array((images[cat][ix]).cpu()).astype(np.uint8).squeeze()\n",
        "            im = Image.fromarray(im)\n",
        "            img.paste(im, (xoffset + cat * width, yoffset))\n",
        "\n",
        "    return img\n",
        "\n",
        "\n",
        "def imshow(img, title=''):\n",
        "    fig = plt.gcf()\n",
        "    fig.canvas.set_window_title(title)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(img, interpolation='none')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def imsave(img, path):\n",
        "    im = Image.fromarray(img.cpu().numpy().astype(np.uint8).squeeze())\n",
        "    im.save(path)\n",
        "\n",
        "\n",
        "class Progbar(object):\n",
        "    \"\"\"Displays a progress bar.\n",
        "\n",
        "    Arguments:\n",
        "        target: Total number of steps expected, None if unknown.\n",
        "        width: Progress bar width on screen.\n",
        "        verbose: Verbosity mode, 0 (silent), 1 (verbose), 2 (semi-verbose)\n",
        "        stateful_metrics: Iterable of string names of metrics that\n",
        "            should *not* be averaged over time. Metrics in this list\n",
        "            will be displayed as-is. All others will be averaged\n",
        "            by the progbar before display.\n",
        "        interval: Minimum visual progress update interval (in seconds).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, target, width=25, verbose=1, interval=0.05,\n",
        "                 stateful_metrics=None):\n",
        "        self.target = target\n",
        "        self.width = width\n",
        "        self.verbose = verbose\n",
        "        self.interval = interval\n",
        "        if stateful_metrics:\n",
        "            self.stateful_metrics = set(stateful_metrics)\n",
        "        else:\n",
        "            self.stateful_metrics = set()\n",
        "\n",
        "        self._dynamic_display = ((hasattr(sys.stdout, 'isatty') and\n",
        "                                  sys.stdout.isatty()) or\n",
        "                                 'ipykernel' in sys.modules or\n",
        "                                 'posix' in sys.modules)\n",
        "        self._total_width = 0\n",
        "        self._seen_so_far = 0\n",
        "        # We use a dict + list to avoid garbage collection\n",
        "        # issues found in OrderedDict\n",
        "        self._values = {}\n",
        "        self._values_order = []\n",
        "        self._start = time.time()\n",
        "        self._last_update = 0\n",
        "\n",
        "    def update(self, current, values=None):\n",
        "        \"\"\"Updates the progress bar.\n",
        "\n",
        "        Arguments:\n",
        "            current: Index of current step.\n",
        "            values: List of tuples:\n",
        "                `(name, value_for_last_step)`.\n",
        "                If `name` is in `stateful_metrics`,\n",
        "                `value_for_last_step` will be displayed as-is.\n",
        "                Else, an average of the metric over time will be displayed.\n",
        "        \"\"\"\n",
        "        values = values or []\n",
        "        for k, v in values:\n",
        "            if k not in self._values_order:\n",
        "                self._values_order.append(k)\n",
        "            if k not in self.stateful_metrics:\n",
        "                if k not in self._values:\n",
        "                    self._values[k] = [v * (current - self._seen_so_far),\n",
        "                                       current - self._seen_so_far]\n",
        "                else:\n",
        "                    self._values[k][0] += v * (current - self._seen_so_far)\n",
        "                    self._values[k][1] += (current - self._seen_so_far)\n",
        "            else:\n",
        "                self._values[k] = v\n",
        "        self._seen_so_far = current\n",
        "\n",
        "        now = time.time()\n",
        "        info = ' - %.0fs' % (now - self._start)\n",
        "        if self.verbose == 1:\n",
        "            if (now - self._last_update < self.interval and\n",
        "                    self.target is not None and current < self.target):\n",
        "                return\n",
        "\n",
        "            prev_total_width = self._total_width\n",
        "            if self._dynamic_display:\n",
        "                sys.stdout.write('\\b' * prev_total_width)\n",
        "                sys.stdout.write('\\r')\n",
        "            else:\n",
        "                sys.stdout.write('\\n')\n",
        "\n",
        "            if self.target is not None:\n",
        "                numdigits = int(np.floor(np.log10(self.target))) + 1\n",
        "                barstr = '%%%dd/%d [' % (numdigits, self.target)\n",
        "                bar = barstr % current\n",
        "                prog = float(current) / self.target\n",
        "                prog_width = int(self.width * prog)\n",
        "                if prog_width > 0:\n",
        "                    bar += ('=' * (prog_width - 1))\n",
        "                    if current < self.target:\n",
        "                        bar += '>'\n",
        "                    else:\n",
        "                        bar += '='\n",
        "                bar += ('.' * (self.width - prog_width))\n",
        "                bar += ']'\n",
        "            else:\n",
        "                bar = '%7d/Unknown' % current\n",
        "\n",
        "            self._total_width = len(bar)\n",
        "            sys.stdout.write(bar)\n",
        "\n",
        "            if current:\n",
        "                time_per_unit = (now - self._start) / current\n",
        "            else:\n",
        "                time_per_unit = 0\n",
        "            if self.target is not None and current < self.target:\n",
        "                eta = time_per_unit * (self.target - current)\n",
        "                if eta > 3600:\n",
        "                    eta_format = '%d:%02d:%02d' % (eta // 3600,\n",
        "                                                   (eta % 3600) // 60,\n",
        "                                                   eta % 60)\n",
        "                elif eta > 60:\n",
        "                    eta_format = '%d:%02d' % (eta // 60, eta % 60)\n",
        "                else:\n",
        "                    eta_format = '%ds' % eta\n",
        "\n",
        "                info = ' - ETA: %s' % eta_format\n",
        "            else:\n",
        "                if time_per_unit >= 1:\n",
        "                    info += ' %.0fs/step' % time_per_unit\n",
        "                elif time_per_unit >= 1e-3:\n",
        "                    info += ' %.0fms/step' % (time_per_unit * 1e3)\n",
        "                else:\n",
        "                    info += ' %.0fus/step' % (time_per_unit * 1e6)\n",
        "\n",
        "            for k in self._values_order:\n",
        "                info += ' - %s:' % k\n",
        "                if isinstance(self._values[k], list):\n",
        "                    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n",
        "                    if abs(avg) > 1e-3:\n",
        "                        info += ' %.4f' % avg\n",
        "                    else:\n",
        "                        info += ' %.4e' % avg\n",
        "                else:\n",
        "                    info += ' %s' % self._values[k]\n",
        "\n",
        "            self._total_width += len(info)\n",
        "            if prev_total_width > self._total_width:\n",
        "                info += (' ' * (prev_total_width - self._total_width))\n",
        "\n",
        "            if self.target is not None and current >= self.target:\n",
        "                info += '\\n'\n",
        "\n",
        "            sys.stdout.write(info)\n",
        "            sys.stdout.flush()\n",
        "\n",
        "        elif self.verbose == 2:\n",
        "            if self.target is None or current >= self.target:\n",
        "                for k in self._values_order:\n",
        "                    info += ' - %s:' % k\n",
        "                    avg = np.mean(self._values[k][0] / max(1, self._values[k][1]))\n",
        "                    if avg > 1e-3:\n",
        "                        info += ' %.4f' % avg\n",
        "                    else:\n",
        "                        info += ' %.4e' % avg\n",
        "                info += '\\n'\n",
        "\n",
        "                sys.stdout.write(info)\n",
        "                sys.stdout.flush()\n",
        "\n",
        "        self._last_update = now\n",
        "\n",
        "    def add(self, n, values=None):\n",
        "        self.update(self._seen_so_far + n, values)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNdW2FlY0_ey",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title fix dataset delimiter ([Yukariin /edge-connect](https://github.com/Yukariin/edge-connect/blob/master/src/utils.py))\n",
        "\n",
        "import os\n",
        "import glob\n",
        "import scipy\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torchvision.transforms.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "from scipy.misc import imread\n",
        "from skimage.feature import canny\n",
        "from skimage.color import rgb2gray, gray2rgb\n",
        "from .utils import create_mask\n",
        "\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, config, flist, edge_flist, mask_flist, augment=True, training=True):\n",
        "        super(Dataset, self).__init__()\n",
        "        self.augment = augment\n",
        "        self.training = training\n",
        "        self.data = self.load_flist(flist)\n",
        "        self.edge_data = self.load_flist(edge_flist)\n",
        "        self.mask_data = self.load_flist(mask_flist)\n",
        "\n",
        "        self.input_size = config.INPUT_SIZE\n",
        "        self.sigma = config.SIGMA\n",
        "        self.edge = config.EDGE\n",
        "        self.mask = config.MASK\n",
        "        self.nms = config.NMS\n",
        "\n",
        "        # in test mode, there's a one-to-one relationship between mask and image\n",
        "        # masks are loaded non random\n",
        "        if config.MODE == 2:\n",
        "            self.mask = 6\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        try:\n",
        "            item = self.load_item(index)\n",
        "        except:\n",
        "            print('loading error: ' + self.data[index])\n",
        "            item = self.load_item(0)\n",
        "\n",
        "        return item\n",
        "\n",
        "    def load_name(self, index):\n",
        "        name = self.data[index]\n",
        "        return os.path.basename(name)\n",
        "\n",
        "    def load_item(self, index):\n",
        "\n",
        "        size = self.input_size\n",
        "\n",
        "        # load image\n",
        "        img = imread(self.data[index])\n",
        "\n",
        "        # gray to rgb\n",
        "        if len(img.shape) < 3:\n",
        "            img = gray2rgb(img)\n",
        "\n",
        "        # resize/crop if needed\n",
        "        if size != 0:\n",
        "            img = self.resize(img, size, size)\n",
        "\n",
        "        # create grayscale image\n",
        "        img_gray = rgb2gray(img)\n",
        "\n",
        "        # load mask\n",
        "        mask = self.load_mask(img, index)\n",
        "\n",
        "        # load edge\n",
        "        edge = self.load_edge(img_gray, index, mask)\n",
        "\n",
        "        # augment data\n",
        "        if self.augment and np.random.binomial(1, 0.5) > 0:\n",
        "            img = img[:, ::-1, ...]\n",
        "            img_gray = img_gray[:, ::-1, ...]\n",
        "            edge = edge[:, ::-1, ...]\n",
        "            mask = mask[:, ::-1, ...]\n",
        "\n",
        "        return self.to_tensor(img), self.to_tensor(img_gray), self.to_tensor(edge), self.to_tensor(mask)\n",
        "\n",
        "    def load_edge(self, img, index, mask):\n",
        "        sigma = self.sigma\n",
        "\n",
        "        # in test mode images are masked (with masked regions),\n",
        "        # using 'mask' parameter prevents canny to detect edges for the masked regions\n",
        "        mask = None if self.training else (1 - mask / 255).astype(np.bool)\n",
        "\n",
        "        # canny\n",
        "        if self.edge == 1:\n",
        "            # no edge\n",
        "            if sigma == -1:\n",
        "                return np.zeros(img.shape).astype(np.float)\n",
        "\n",
        "            # random sigma\n",
        "            if sigma == 0:\n",
        "                sigma = random.randint(1, 4)\n",
        "\n",
        "            return canny(img, sigma=sigma, mask=mask).astype(np.float)\n",
        "\n",
        "        # external\n",
        "        else:\n",
        "            imgh, imgw = img.shape[0:2]\n",
        "            edge = imread(self.edge_data[index])\n",
        "            edge = self.resize(edge, imgh, imgw)\n",
        "\n",
        "            # non-max suppression\n",
        "            if self.nms == 1:\n",
        "                edge = edge * canny(img, sigma=sigma, mask=mask)\n",
        "\n",
        "            return edge\n",
        "\n",
        "    def load_mask(self, img, index):\n",
        "        imgh, imgw = img.shape[0:2]\n",
        "        mask_type = self.mask\n",
        "\n",
        "        # external + random block\n",
        "        if mask_type == 4:\n",
        "            mask_type = 1 if np.random.binomial(1, 0.5) == 1 else 3\n",
        "\n",
        "        # external + random block + half\n",
        "        elif mask_type == 5:\n",
        "            mask_type = np.random.randint(1, 4)\n",
        "\n",
        "        # random block\n",
        "        if mask_type == 1:\n",
        "            return create_mask(imgw, imgh, imgw // 2, imgh // 2)\n",
        "\n",
        "        # half\n",
        "        if mask_type == 2:\n",
        "            # randomly choose right or left\n",
        "            return create_mask(imgw, imgh, imgw // 2, imgh, 0 if random.random() < 0.5 else imgw // 2, 0)\n",
        "\n",
        "        # external\n",
        "        if mask_type == 3:\n",
        "            mask_index = random.randint(0, len(self.mask_data) - 1)\n",
        "            mask = imread(self.mask_data[mask_index])\n",
        "            mask = self.resize(mask, imgh, imgw)\n",
        "            mask = (mask > 0).astype(np.uint8) * 255       # threshold due to interpolation\n",
        "            return mask\n",
        "\n",
        "        # test mode: load mask non random\n",
        "        if mask_type == 6:\n",
        "            mask = imread(self.mask_data[index])\n",
        "            mask = self.resize(mask, imgh, imgw, centerCrop=False)\n",
        "            mask = rgb2gray(mask)\n",
        "            mask = (mask > 0).astype(np.uint8) * 255\n",
        "            return mask\n",
        "\n",
        "    def to_tensor(self, img):\n",
        "        img = Image.fromarray(img)\n",
        "        img_t = F.to_tensor(img).float()\n",
        "        return img_t\n",
        "\n",
        "    def resize(self, img, height, width, centerCrop=True):\n",
        "        imgh, imgw = img.shape[0:2]\n",
        "\n",
        "        if centerCrop and imgh != imgw:\n",
        "            # center crop\n",
        "            side = np.minimum(imgh, imgw)\n",
        "            j = (imgh - side) // 2\n",
        "            i = (imgw - side) // 2\n",
        "            img = img[j:j + side, i:i + side, ...]\n",
        "\n",
        "        img = scipy.misc.imresize(img, [height, width])\n",
        "\n",
        "        return img\n",
        "\n",
        "    def load_flist(self, flist):\n",
        "        if isinstance(flist, list):\n",
        "            return flist\n",
        "\n",
        "        # flist: image file path, image directory path, text file flist path\n",
        "        if isinstance(flist, str):\n",
        "            if os.path.isdir(flist):\n",
        "                flist = list(glob.glob(flist + '/*.jpg')) + list(glob.glob(flist + '/*.png'))\n",
        "                flist.sort()\n",
        "                return flist\n",
        "\n",
        "            if os.path.isfile(flist):\n",
        "                try:\n",
        "                    return np.genfromtxt(flist, dtype=np.str, delimiter='\\n', encoding='utf-8')\n",
        "                except:\n",
        "                    return [flist]\n",
        "\n",
        "        return []\n",
        "\n",
        "    def create_iterator(self, batch_size):\n",
        "        while True:\n",
        "            sample_loader = DataLoader(\n",
        "                dataset=self,\n",
        "                batch_size=batch_size,\n",
        "                drop_last=True\n",
        "            )\n",
        "\n",
        "            for item in sample_loader:\n",
        "                yield item\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAdscM1moO-C",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Training config\n",
        "%%writefile /content/training-checkpoints/config.yml\n",
        "MODE: 1             # 1: train, 2: test, 3: eval\n",
        "MODEL: 3            # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model\n",
        "MASK: 3             # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)\n",
        "EDGE: 1             # 1: canny, 2: external\n",
        "NMS: 1              # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny\n",
        "SEED: 10            # random seed\n",
        "GPU: [0]            # list of gpu ids\n",
        "DEBUG: 0            # turns on debugging mode\n",
        "VERBOSE: 0          # turns on verbose mode in the output console\n",
        "\n",
        "TRAIN_FLIST: /content/train/train.tflist\n",
        "VAL_FLIST: /content/val/val.tflist\n",
        "TEST_FLIST: /content/val/val.tflist\n",
        "\n",
        "TRAIN_EDGE_FLIST: ./datasets/places2_edges_train.flist\n",
        "VAL_EDGE_FLIST: ./datasets/places2_edges_val.flist\n",
        "TEST_EDGE_FLIST: ./datasets/places2_edges_test.flist\n",
        "\n",
        "TRAIN_MASK_FLIST: /content/mask_train/mask_train.tflist\n",
        "VAL_MASK_FLIST: /content/mask_val/mask_val.tflist\n",
        "TEST_MASK_FLIST: /content/mask_val/mask_val.tflist\n",
        "\n",
        "LR: 0.0001                    # learning rate\n",
        "D2G_LR: 0.1                   # discriminator/generator learning rate ratio\n",
        "BETA1: 0.0                    # adam optimizer beta1\n",
        "BETA2: 0.9                    # adam optimizer beta2\n",
        "BATCH_SIZE: 1                 # input batch size for training\n",
        "INPUT_SIZE: 256               # input image size for training 0 for original size\n",
        "SIGMA: 2                      # standard deviation of the Gaussian filter used in Canny edge detector (0: random, -1: no edge)\n",
        "MAX_ITERS: 1000000                # maximum number of iterations to train the model\n",
        "\n",
        "EDGE_THRESHOLD: 0.5           # edge detection threshold\n",
        "L1_LOSS_WEIGHT: 1             # l1 loss weight\n",
        "FM_LOSS_WEIGHT: 10            # feature-matching loss weight\n",
        "STYLE_LOSS_WEIGHT: 250        # style loss weight\n",
        "CONTENT_LOSS_WEIGHT: 0.1      # perceptual loss weight\n",
        "INPAINT_ADV_LOSS_WEIGHT: 0.1  # adversarial loss weight\n",
        "\n",
        "GAN_LOSS: nsgan               # nsgan | lsgan | hinge\n",
        "GAN_POOL_SIZE: 0              # fake images pool size\n",
        "\n",
        "SAVE_INTERVAL: 200           # how many iterations to wait before saving model (0: never)\n",
        "SAMPLE_INTERVAL: 1000         # how many iterations to wait before sampling (0: never)\n",
        "SAMPLE_SIZE: 1               # number of images to sample\n",
        "EVAL_INTERVAL: 0              # how many iterations to wait before model evaluation (0: never)\n",
        "LOG_INTERVAL: 10              # how many iterations to wait before logging training status (0: never)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSPXmERCWpJ4",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create empty folders\n",
        "!mkdir /content/training-checkpoints/\n",
        "!mkdir /content/train/\n",
        "!mkdir /content/val/\n",
        "!mkdir /content/mask_train/\n",
        "!mkdir /content/mask_val/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H--bAmNAJdms",
        "colab_type": "text"
      },
      "source": [
        "Input all your data.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euuxf2YHlw7z",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install miniconda and dependencies\n",
        "%cd /content/\n",
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install pytorch==1.1 cudatoolkit torchvision -c pytorch -y\n",
        "%cd /content/edge-connect\n",
        "!pip install -r requirements.txt\n",
        "!conda install ipykernel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Znym_DLBCF6g",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title differentialbe augmentation in models.py (experimental, should be fixed)\n",
        "%%writefile /content/edge-connect/src/models.py\n",
        "\n",
        "\n",
        "# Differentiable Augmentation for Data-Efficient GAN Training\n",
        "# Shengyu Zhao, Zhijian Liu, Ji Lin, Jun-Yan Zhu, and Song Han\n",
        "# https://arxiv.org/pdf/2006.10738\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "policy = 'color,translation,cutout' \n",
        "\n",
        "def DiffAugment(x, policy='', channels_first=True):\n",
        "    if policy:\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 3, 1, 2)\n",
        "        for p in policy.split(','):\n",
        "            for f in AUGMENT_FNS[p]:\n",
        "                x = f(x)\n",
        "        if not channels_first:\n",
        "            x = x.permute(0, 2, 3, 1)\n",
        "        x = x.contiguous()\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_brightness(x):\n",
        "    x = x + (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) - 0.5)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_saturation(x):\n",
        "    x_mean = x.mean(dim=1, keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) * 2) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_contrast(x):\n",
        "    x_mean = x.mean(dim=[1, 2, 3], keepdim=True)\n",
        "    x = (x - x_mean) * (torch.rand(x.size(0), 1, 1, 1, dtype=x.dtype, device=x.device) + 0.5) + x_mean\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_translation(x, ratio=0.125):\n",
        "    shift_x, shift_y = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    translation_x = torch.randint(-shift_x, shift_x + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    translation_y = torch.randint(-shift_y, shift_y + 1, size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(2), dtype=torch.long, device=x.device),\n",
        "        torch.arange(x.size(3), dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + translation_x + 1, 0, x.size(2) + 1)\n",
        "    grid_y = torch.clamp(grid_y + translation_y + 1, 0, x.size(3) + 1)\n",
        "    x_pad = F.pad(x, [1, 1, 1, 1, 0, 0, 0, 0])\n",
        "    x = x_pad.permute(0, 2, 3, 1).contiguous()[grid_batch, grid_x, grid_y].permute(0, 3, 1, 2)\n",
        "    return x\n",
        "\n",
        "\n",
        "def rand_cutout(x, ratio=0.5):\n",
        "    cutout_size = int(x.size(2) * ratio + 0.5), int(x.size(3) * ratio + 0.5)\n",
        "    offset_x = torch.randint(0, x.size(2) + (1 - cutout_size[0] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    offset_y = torch.randint(0, x.size(3) + (1 - cutout_size[1] % 2), size=[x.size(0), 1, 1], device=x.device)\n",
        "    grid_batch, grid_x, grid_y = torch.meshgrid(\n",
        "        torch.arange(x.size(0), dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[0], dtype=torch.long, device=x.device),\n",
        "        torch.arange(cutout_size[1], dtype=torch.long, device=x.device),\n",
        "    )\n",
        "    grid_x = torch.clamp(grid_x + offset_x - cutout_size[0] // 2, min=0, max=x.size(2) - 1)\n",
        "    grid_y = torch.clamp(grid_y + offset_y - cutout_size[1] // 2, min=0, max=x.size(3) - 1)\n",
        "    mask = torch.ones(x.size(0), x.size(2), x.size(3), dtype=x.dtype, device=x.device)\n",
        "    mask[grid_batch, grid_x, grid_y] = 0\n",
        "    x = x * mask.unsqueeze(1)\n",
        "    return x\n",
        "\n",
        "\n",
        "AUGMENT_FNS = {\n",
        "    'color': [rand_brightness, rand_saturation, rand_contrast],\n",
        "    'translation': [rand_translation],\n",
        "    'cutout': [rand_cutout],\n",
        "}\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from .networks import InpaintGenerator, EdgeGenerator, Discriminator\n",
        "from .loss import AdversarialLoss, PerceptualLoss, StyleLoss\n",
        "\n",
        "\n",
        "class BaseModel(nn.Module):\n",
        "    def __init__(self, name, config):\n",
        "        super(BaseModel, self).__init__()\n",
        "\n",
        "        self.name = name\n",
        "        self.config = config\n",
        "        self.iteration = 0\n",
        "\n",
        "        self.gen_weights_path = os.path.join(config.PATH, name + '_gen.pth')\n",
        "        self.dis_weights_path = os.path.join(config.PATH, name + '_dis.pth')\n",
        "\n",
        "    def load(self):\n",
        "        if os.path.exists(self.gen_weights_path):\n",
        "            print('Loading %s generator...' % self.name)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                data = torch.load(self.gen_weights_path)\n",
        "            else:\n",
        "                data = torch.load(self.gen_weights_path, map_location=lambda storage, loc: storage)\n",
        "\n",
        "            self.generator.load_state_dict(data['generator'])\n",
        "            self.iteration = data['iteration']\n",
        "\n",
        "        # load discriminator only when training\n",
        "        if self.config.MODE == 1 and os.path.exists(self.dis_weights_path):\n",
        "            print('Loading %s discriminator...' % self.name)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                data = torch.load(self.dis_weights_path)\n",
        "            else:\n",
        "                data = torch.load(self.dis_weights_path, map_location=lambda storage, loc: storage)\n",
        "\n",
        "            self.discriminator.load_state_dict(data['discriminator'])\n",
        "\n",
        "    def save(self):\n",
        "        print('\\nsaving %s...\\n' % self.name)\n",
        "        torch.save({\n",
        "            'iteration': self.iteration,\n",
        "            'generator': self.generator.state_dict()\n",
        "        }, self.gen_weights_path)\n",
        "\n",
        "        torch.save({\n",
        "            'discriminator': self.discriminator.state_dict()\n",
        "        }, self.dis_weights_path)\n",
        "\n",
        "\n",
        "class EdgeModel(BaseModel):\n",
        "    def __init__(self, config):\n",
        "        super(EdgeModel, self).__init__('EdgeModel', config)\n",
        "\n",
        "        # generator input: [grayscale(1) + edge(1) + mask(1)]\n",
        "        # discriminator input: (grayscale(1) + edge(1))\n",
        "        generator = EdgeGenerator(use_spectral_norm=True)\n",
        "        discriminator = Discriminator(in_channels=2, use_sigmoid=config.GAN_LOSS != 'hinge')\n",
        "        if len(config.GPU) > 1:\n",
        "            generator = nn.DataParallel(generator, config.GPU)\n",
        "            discriminator = nn.DataParallel(discriminator, config.GPU)\n",
        "        l1_loss = nn.L1Loss()\n",
        "        adversarial_loss = AdversarialLoss(type=config.GAN_LOSS)\n",
        "\n",
        "        self.add_module('generator', generator)\n",
        "        self.add_module('discriminator', discriminator)\n",
        "\n",
        "        self.add_module('l1_loss', l1_loss)\n",
        "        self.add_module('adversarial_loss', adversarial_loss)\n",
        "\n",
        "        self.gen_optimizer = optim.Adam(\n",
        "            params=generator.parameters(),\n",
        "            lr=float(config.LR),\n",
        "            betas=(config.BETA1, config.BETA2)\n",
        "        )\n",
        "\n",
        "        self.dis_optimizer = optim.Adam(\n",
        "            params=discriminator.parameters(),\n",
        "            lr=float(config.LR) * float(config.D2G_LR),\n",
        "            betas=(config.BETA1, config.BETA2)\n",
        "        )\n",
        "\n",
        "    def process(self, images, edges, masks):\n",
        "        self.iteration += 1\n",
        "\n",
        "\n",
        "        # zero optimizers\n",
        "        self.gen_optimizer.zero_grad()\n",
        "        self.dis_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        # process outputs\n",
        "        outputs = self(images, edges, masks)\n",
        "        gen_loss = 0\n",
        "        dis_loss = 0\n",
        "\n",
        "\n",
        "        # discriminator loss\n",
        "        dis_input_real = torch.cat((images, edges), dim=1)\n",
        "        dis_input_fake = torch.cat((images, outputs.detach()), dim=1)\n",
        "        #real_scores = Discriminator(DiffAugment(reals, policy=policy))\n",
        "        dis_real, dis_real_feat = self.discriminator(DiffAugment(dis_input_real, policy=policy))        # in: (grayscale(1) + edge(1))\n",
        "        dis_fake, dis_fake_feat = self.discriminator(DiffAugment(dis_input_fake, policy=policy))        # in: (grayscale(1) + edge(1))\n",
        "        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n",
        "        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n",
        "        dis_loss += (dis_real_loss + dis_fake_loss) / 2\n",
        "\n",
        "\n",
        "        # generator adversarial loss\n",
        "        gen_input_fake = torch.cat((images, outputs), dim=1)\n",
        "        gen_fake, gen_fake_feat = self.discriminator(DiffAugment(gen_input_fake, policy=policy))         # in: (grayscale(1) + edge(1))\n",
        "        gen_gan_loss = self.adversarial_loss(gen_fake, True, False)\n",
        "        gen_loss += gen_gan_loss\n",
        "\n",
        "\n",
        "        # generator feature matching loss\n",
        "        gen_fm_loss = 0\n",
        "        for i in range(len(dis_real_feat)):\n",
        "            gen_fm_loss += self.l1_loss(gen_fake_feat[i], dis_real_feat[i].detach())\n",
        "        gen_fm_loss = gen_fm_loss * self.config.FM_LOSS_WEIGHT\n",
        "        gen_loss += gen_fm_loss\n",
        "\n",
        "\n",
        "        # create logs\n",
        "        logs = [\n",
        "            (\"l_d1\", dis_loss.item()),\n",
        "            (\"l_g1\", gen_gan_loss.item()),\n",
        "            (\"l_fm\", gen_fm_loss.item()),\n",
        "        ]\n",
        "\n",
        "        return outputs, gen_loss, dis_loss, logs\n",
        "\n",
        "    def forward(self, images, edges, masks):\n",
        "        edges_masked = (edges * (1 - masks))\n",
        "        images_masked = (images * (1 - masks)) + masks\n",
        "        inputs = torch.cat((images_masked, edges_masked, masks), dim=1)\n",
        "        outputs = self.generator(inputs)                                    # in: [grayscale(1) + edge(1) + mask(1)]\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, gen_loss=None, dis_loss=None):\n",
        "        if dis_loss is not None:\n",
        "            dis_loss.backward()\n",
        "        self.dis_optimizer.step()\n",
        "\n",
        "        if gen_loss is not None:\n",
        "            gen_loss.backward()\n",
        "        self.gen_optimizer.step()\n",
        "\n",
        "\n",
        "class InpaintingModel(BaseModel):\n",
        "    def __init__(self, config):\n",
        "        super(InpaintingModel, self).__init__('InpaintingModel', config)\n",
        "\n",
        "        # generator input: [rgb(3) + edge(1)]\n",
        "        # discriminator input: [rgb(3)]\n",
        "        generator = InpaintGenerator()\n",
        "        discriminator = Discriminator(in_channels=3, use_sigmoid=config.GAN_LOSS != 'hinge')\n",
        "        if len(config.GPU) > 1:\n",
        "            generator = nn.DataParallel(generator, config.GPU)\n",
        "            discriminator = nn.DataParallel(discriminator , config.GPU)\n",
        "\n",
        "        l1_loss = nn.L1Loss()\n",
        "        perceptual_loss = PerceptualLoss()\n",
        "        style_loss = StyleLoss()\n",
        "        adversarial_loss = AdversarialLoss(type=config.GAN_LOSS)\n",
        "\n",
        "        self.add_module('generator', generator)\n",
        "        self.add_module('discriminator', discriminator)\n",
        "\n",
        "        self.add_module('l1_loss', l1_loss)\n",
        "        self.add_module('perceptual_loss', perceptual_loss)\n",
        "        self.add_module('style_loss', style_loss)\n",
        "        self.add_module('adversarial_loss', adversarial_loss)\n",
        "\n",
        "        self.gen_optimizer = optim.Adam(\n",
        "            params=generator.parameters(),\n",
        "            lr=float(config.LR),\n",
        "            betas=(config.BETA1, config.BETA2)\n",
        "        )\n",
        "\n",
        "        self.dis_optimizer = optim.Adam(\n",
        "            params=discriminator.parameters(),\n",
        "            lr=float(config.LR) * float(config.D2G_LR),\n",
        "            betas=(config.BETA1, config.BETA2)\n",
        "        )\n",
        "\n",
        "    def process(self, images, edges, masks):\n",
        "        self.iteration += 1\n",
        "\n",
        "        # zero optimizers\n",
        "        self.gen_optimizer.zero_grad()\n",
        "        self.dis_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        # process outputs\n",
        "        outputs = self(images, edges, masks)\n",
        "        gen_loss = 0\n",
        "        dis_loss = 0\n",
        "\n",
        "\n",
        "        # discriminator loss\n",
        "        dis_input_real = images\n",
        "        dis_input_fake = outputs.detach()\n",
        "        #real_scores = Discriminator(DiffAugment(reals, policy=policy))\n",
        "        dis_real, _ = self.discriminator(DiffAugment(dis_input_real, policy=policy))                    # in: [rgb(3)]\n",
        "        dis_fake, _ = self.discriminator(DiffAugment(dis_input_fake, policy=policy))                    # in: [rgb(3)]\n",
        "        dis_real_loss = self.adversarial_loss(dis_real, True, True)\n",
        "        dis_fake_loss = self.adversarial_loss(dis_fake, False, True)\n",
        "        dis_loss += (dis_real_loss + dis_fake_loss) / 2\n",
        "\n",
        "\n",
        "        # generator adversarial loss\n",
        "        gen_input_fake = outputs\n",
        "        #real_scores = Discriminator(DiffAugment(reals, policy=policy))\n",
        "        gen_fake, _ = self.discriminator(DiffAugment(gen_input_fake, policy=policy))                  # in: [rgb(3)]\n",
        "        gen_gan_loss = self.adversarial_loss(gen_fake, True, False) * self.config.INPAINT_ADV_LOSS_WEIGHT\n",
        "        gen_loss += gen_gan_loss\n",
        "\n",
        "\n",
        "        # generator l1 loss\n",
        "        gen_l1_loss = self.l1_loss(outputs, images) * self.config.L1_LOSS_WEIGHT / torch.mean(masks)\n",
        "        gen_loss += gen_l1_loss\n",
        "\n",
        "\n",
        "        # generator perceptual loss\n",
        "        gen_content_loss = self.perceptual_loss(outputs, images)\n",
        "        gen_content_loss = gen_content_loss * self.config.CONTENT_LOSS_WEIGHT\n",
        "        gen_loss += gen_content_loss\n",
        "\n",
        "\n",
        "        # generator style loss\n",
        "        gen_style_loss = self.style_loss(outputs * masks, images * masks)\n",
        "        gen_style_loss = gen_style_loss * self.config.STYLE_LOSS_WEIGHT\n",
        "        gen_loss += gen_style_loss\n",
        "\n",
        "\n",
        "        # create logs\n",
        "        logs = [\n",
        "            (\"l_d2\", dis_loss.item()),\n",
        "            (\"l_g2\", gen_gan_loss.item()),\n",
        "            (\"l_l1\", gen_l1_loss.item()),\n",
        "            (\"l_per\", gen_content_loss.item()),\n",
        "            (\"l_sty\", gen_style_loss.item()),\n",
        "        ]\n",
        "\n",
        "        return outputs, gen_loss, dis_loss, logs\n",
        "\n",
        "    def forward(self, images, edges, masks):\n",
        "        images_masked = (images * (1 - masks).float()) + masks\n",
        "        inputs = torch.cat((images_masked, edges), dim=1)\n",
        "        outputs = self.generator(inputs)                                    # in: [rgb(3) + edge(1)]\n",
        "        return outputs\n",
        "\n",
        "    def backward(self, gen_loss=None, dis_loss=None):\n",
        "        dis_loss.backward()\n",
        "        self.dis_optimizer.step()\n",
        "\n",
        "        gen_loss.backward()\n",
        "        self.gen_optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wE0Qa3_WRft",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Tensorboard support in edge_connect.py (experimental, should be tested)\n",
        "%%writefile /content/edge-connect/src/edge_connect.py\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from .dataset import Dataset\n",
        "from .models import EdgeModel, InpaintingModel\n",
        "from .utils import Progbar, create_dir, stitch_images, imsave\n",
        "from .metrics import PSNR, EdgeAccuracy\n",
        "\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()\n",
        "#Writer will output to ./runs/ directory by default.\n",
        "\n",
        "class EdgeConnect():\n",
        "    def __init__(self, config):\n",
        "        self.config = config\n",
        "\n",
        "        if config.MODEL == 1:\n",
        "            model_name = 'edge'\n",
        "        elif config.MODEL == 2:\n",
        "            model_name = 'inpaint'\n",
        "        elif config.MODEL == 3:\n",
        "            model_name = 'edge_inpaint'\n",
        "        elif config.MODEL == 4:\n",
        "            model_name = 'joint'\n",
        "\n",
        "        self.debug = False\n",
        "        self.model_name = model_name\n",
        "        self.edge_model = EdgeModel(config).to(config.DEVICE)\n",
        "        self.inpaint_model = InpaintingModel(config).to(config.DEVICE)\n",
        "\n",
        "        self.psnr = PSNR(255.0).to(config.DEVICE)\n",
        "        self.edgeacc = EdgeAccuracy(config.EDGE_THRESHOLD).to(config.DEVICE)\n",
        "\n",
        "        # test mode\n",
        "        if self.config.MODE == 2:\n",
        "            self.test_dataset = Dataset(config, config.TEST_FLIST, config.TEST_EDGE_FLIST, config.TEST_MASK_FLIST, augment=False, training=False)\n",
        "        else:\n",
        "            self.train_dataset = Dataset(config, config.TRAIN_FLIST, config.TRAIN_EDGE_FLIST, config.TRAIN_MASK_FLIST, augment=True, training=True)\n",
        "            self.val_dataset = Dataset(config, config.VAL_FLIST, config.VAL_EDGE_FLIST, config.VAL_MASK_FLIST, augment=False, training=True)\n",
        "            self.sample_iterator = self.val_dataset.create_iterator(config.SAMPLE_SIZE)\n",
        "\n",
        "        self.samples_path = os.path.join(config.PATH, 'samples')\n",
        "        self.results_path = os.path.join(config.PATH, 'results')\n",
        "\n",
        "        if config.RESULTS is not None:\n",
        "            self.results_path = os.path.join(config.RESULTS)\n",
        "\n",
        "        if config.DEBUG is not None and config.DEBUG != 0:\n",
        "            self.debug = True\n",
        "\n",
        "        self.log_file = os.path.join(config.PATH, 'log_' + model_name + '.dat')\n",
        "\n",
        "    def load(self):\n",
        "        if self.config.MODEL == 1:\n",
        "            self.edge_model.load()\n",
        "\n",
        "        elif self.config.MODEL == 2:\n",
        "            self.inpaint_model.load()\n",
        "\n",
        "        else:\n",
        "            self.edge_model.load()\n",
        "            self.inpaint_model.load()\n",
        "\n",
        "    def save(self):\n",
        "        if self.config.MODEL == 1:\n",
        "            self.edge_model.save()\n",
        "\n",
        "        elif self.config.MODEL == 2 or self.config.MODEL == 3:\n",
        "            self.inpaint_model.save()\n",
        "\n",
        "        else:\n",
        "            self.edge_model.save()\n",
        "            self.inpaint_model.save()\n",
        "\n",
        "    def train(self):\n",
        "        train_loader = DataLoader(\n",
        "            dataset=self.train_dataset,\n",
        "            batch_size=self.config.BATCH_SIZE,\n",
        "            num_workers=4,\n",
        "            drop_last=True,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        epoch = 0\n",
        "        keep_training = True\n",
        "        model = self.config.MODEL\n",
        "        max_iteration = int(float((self.config.MAX_ITERS)))\n",
        "        total = len(self.train_dataset)\n",
        "\n",
        "        if total == 0:\n",
        "            print('No training data was provided! Check \\'TRAIN_FLIST\\' value in the configuration file.')\n",
        "            return\n",
        "\n",
        "        while(keep_training):\n",
        "            epoch += 1\n",
        "            print('\\n\\nTraining epoch: %d' % epoch)\n",
        "\n",
        "            progbar = Progbar(total, width=20, stateful_metrics=['epoch', 'iter'])\n",
        "\n",
        "            for items in train_loader:\n",
        "                self.edge_model.train()\n",
        "                self.inpaint_model.train()\n",
        "\n",
        "                images, images_gray, edges, masks = self.cuda(*items)\n",
        "\n",
        "                # edge model\n",
        "                if model == 1:\n",
        "                    # train\n",
        "                    outputs, gen_loss, dis_loss, logs = self.edge_model.process(images_gray, edges, masks)\n",
        "\n",
        "                    # metrics\n",
        "                    precision, recall = self.edgeacc(edges * masks, outputs * masks)\n",
        "                    logs.append(('precision', precision.item()))\n",
        "                    logs.append(('recall', recall.item()))\n",
        "\n",
        "                    # backward\n",
        "                    self.edge_model.backward(gen_loss, dis_loss)\n",
        "                    iteration = self.edge_model.iteration\n",
        "\n",
        "\n",
        "                # inpaint model\n",
        "                elif model == 2:\n",
        "                    # train\n",
        "                    outputs, gen_loss, dis_loss, logs = self.inpaint_model.process(images, edges, masks)\n",
        "                    outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "                    # metrics\n",
        "                    psnr = self.psnr(self.postprocess(images), self.postprocess(outputs_merged))\n",
        "                    mae = (torch.sum(torch.abs(images - outputs_merged)) / torch.sum(images)).float()\n",
        "                    logs.append(('psnr', psnr.item()))\n",
        "                    logs.append(('mae', mae.item()))\n",
        "\n",
        "                    # backward\n",
        "                    self.inpaint_model.backward(gen_loss, dis_loss)\n",
        "                    iteration = self.inpaint_model.iteration\n",
        "\n",
        "\n",
        "                # inpaint with edge model\n",
        "                elif model == 3:\n",
        "                    # train\n",
        "                    if True or np.random.binomial(1, 0.5) > 0:\n",
        "                        outputs = self.edge_model(images_gray, edges, masks)\n",
        "                        outputs = outputs * masks + edges * (1 - masks)\n",
        "                    else:\n",
        "                        outputs = edges\n",
        "\n",
        "                    outputs, gen_loss, dis_loss, logs = self.inpaint_model.process(images, outputs.detach(), masks)\n",
        "                    outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "                    # metrics\n",
        "                    psnr = self.psnr(self.postprocess(images), self.postprocess(outputs_merged))\n",
        "                    mae = (torch.sum(torch.abs(images - outputs_merged)) / torch.sum(images)).float()\n",
        "                    logs.append(('psnr', psnr.item()))\n",
        "                    logs.append(('mae', mae.item()))\n",
        "\n",
        "                    # backward\n",
        "                    self.inpaint_model.backward(gen_loss, dis_loss)\n",
        "                    iteration = self.inpaint_model.iteration\n",
        "\n",
        "\n",
        "                # joint model\n",
        "                else:\n",
        "                    # train\n",
        "                    e_outputs, e_gen_loss, e_dis_loss, e_logs = self.edge_model.process(images_gray, edges, masks)\n",
        "                    e_outputs = e_outputs * masks + edges * (1 - masks)\n",
        "                    i_outputs, i_gen_loss, i_dis_loss, i_logs = self.inpaint_model.process(images, e_outputs, masks)\n",
        "                    outputs_merged = (i_outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "                    # metrics\n",
        "                    psnr = self.psnr(self.postprocess(images), self.postprocess(outputs_merged))\n",
        "                    mae = (torch.sum(torch.abs(images - outputs_merged)) / torch.sum(images)).float()\n",
        "                    precision, recall = self.edgeacc(edges * masks, e_outputs * masks)\n",
        "                    e_logs.append(('pre', precision.item()))\n",
        "                    e_logs.append(('rec', recall.item()))\n",
        "                    i_logs.append(('psnr', psnr.item()))\n",
        "                    i_logs.append(('mae', mae.item()))\n",
        "                    logs = e_logs + i_logs\n",
        "\n",
        "                    # backward\n",
        "                    self.inpaint_model.backward(i_gen_loss, i_dis_loss)\n",
        "                    self.edge_model.backward(e_gen_loss, e_dis_loss)\n",
        "                    iteration = self.inpaint_model.iteration\n",
        "\n",
        "\n",
        "                if iteration >= max_iteration:\n",
        "                    keep_training = False\n",
        "                    break\n",
        "\n",
        "                logs = [\n",
        "                    (\"epoch\", epoch),\n",
        "                    (\"iter\", iteration),\n",
        "                ] + logs\n",
        "\n",
        "                progbar.add(len(images), values=logs if self.config.VERBOSE else [x for x in logs if not x[0].startswith('l_')])\n",
        "\n",
        "                # log model at checkpoints\n",
        "                if self.config.LOG_INTERVAL and iteration % self.config.LOG_INTERVAL == 0:\n",
        "                    self.log(logs)\n",
        "\n",
        "                # sample model at checkpoints\n",
        "                if self.config.SAMPLE_INTERVAL and iteration % self.config.SAMPLE_INTERVAL == 0:\n",
        "                    self.sample()\n",
        "\n",
        "                # evaluate model at checkpoints\n",
        "                if self.config.EVAL_INTERVAL and iteration % self.config.EVAL_INTERVAL == 0:\n",
        "                    print('\\nstart eval...\\n')\n",
        "                    self.eval()\n",
        "\n",
        "                # save model at checkpoints\n",
        "                if self.config.SAVE_INTERVAL and iteration % self.config.SAVE_INTERVAL == 0:\n",
        "                    self.save()\n",
        "\n",
        "        print('\\nEnd training....')\n",
        "\n",
        "    def eval(self):\n",
        "        val_loader = DataLoader(\n",
        "            dataset=self.val_dataset,\n",
        "            batch_size=self.config.BATCH_SIZE,\n",
        "            drop_last=True,\n",
        "            shuffle=True\n",
        "        )\n",
        "\n",
        "        model = self.config.MODEL\n",
        "        total = len(self.val_dataset)\n",
        "\n",
        "        self.edge_model.eval()\n",
        "        self.inpaint_model.eval()\n",
        "\n",
        "        progbar = Progbar(total, width=20, stateful_metrics=['it'])\n",
        "        iteration = 0\n",
        "\n",
        "        for items in val_loader:\n",
        "            iteration += 1\n",
        "            images, images_gray, edges, masks = self.cuda(*items)\n",
        "\n",
        "            # edge model\n",
        "            if model == 1:\n",
        "                # eval\n",
        "                outputs, gen_loss, dis_loss, logs = self.edge_model.process(images_gray, edges, masks)\n",
        "\n",
        "                # metrics\n",
        "                precision, recall = self.edgeacc(edges * masks, outputs * masks)\n",
        "                logs.append(('precision', precision.item()))\n",
        "                logs.append(('recall', recall.item()))\n",
        "\n",
        "\n",
        "            # inpaint model\n",
        "            elif model == 2:\n",
        "                # eval\n",
        "                outputs, gen_loss, dis_loss, logs = self.inpaint_model.process(images, edges, masks)\n",
        "                outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "                # metrics\n",
        "                psnr = self.psnr(self.postprocess(images), self.postprocess(outputs_merged))\n",
        "                mae = (torch.sum(torch.abs(images - outputs_merged)) / torch.sum(images)).float()\n",
        "                logs.append(('psnr', psnr.item()))\n",
        "                logs.append(('mae', mae.item()))\n",
        "\n",
        "\n",
        "            # inpaint with edge model\n",
        "            elif model == 3:\n",
        "                # eval\n",
        "                outputs = self.edge_model(images_gray, edges, masks)\n",
        "                outputs = outputs * masks + edges * (1 - masks)\n",
        "\n",
        "                outputs, gen_loss, dis_loss, logs = self.inpaint_model.process(images, outputs.detach(), masks)\n",
        "                outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "                # metrics\n",
        "                psnr = self.psnr(self.postprocess(images), self.postprocess(outputs_merged))\n",
        "                mae = (torch.sum(torch.abs(images - outputs_merged)) / torch.sum(images)).float()\n",
        "                logs.append(('psnr', psnr.item()))\n",
        "                logs.append(('mae', mae.item()))\n",
        "                \n",
        "                writer.add_scalar(\"psnr\", psnr, 100)\n",
        "                writer.add_scalar(\"mae\", mae, 100)\n",
        "                writer.add_scalar(\"gen_loss\", gen_loss, 100)\n",
        "                writer.add_scalar(\"dis_loss\", dis_loss, 100)\n",
        "\n",
        "            # joint model\n",
        "            else:\n",
        "                # eval\n",
        "                e_outputs, e_gen_loss, e_dis_loss, e_logs = self.edge_model.process(images_gray, edges, masks)\n",
        "                e_outputs = e_outputs * masks + edges * (1 - masks)\n",
        "                i_outputs, i_gen_loss, i_dis_loss, i_logs = self.inpaint_model.process(images, e_outputs, masks)\n",
        "                outputs_merged = (i_outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "                # metrics\n",
        "                psnr = self.psnr(self.postprocess(images), self.postprocess(outputs_merged))\n",
        "                mae = (torch.sum(torch.abs(images - outputs_merged)) / torch.sum(images)).float()\n",
        "                precision, recall = self.edgeacc(edges * masks, e_outputs * masks)\n",
        "                e_logs.append(('pre', precision.item()))\n",
        "                e_logs.append(('rec', recall.item()))\n",
        "                i_logs.append(('psnr', psnr.item()))\n",
        "                i_logs.append(('mae', mae.item()))\n",
        "                logs = e_logs + i_logs\n",
        "\n",
        "\n",
        "            logs = [(\"it\", iteration), ] + logs\n",
        "            progbar.add(len(images), values=logs)\n",
        "\n",
        "    def test(self):\n",
        "        self.edge_model.eval()\n",
        "        self.inpaint_model.eval()\n",
        "\n",
        "        model = self.config.MODEL\n",
        "        create_dir(self.results_path)\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            dataset=self.test_dataset,\n",
        "            batch_size=1,\n",
        "        )\n",
        "\n",
        "        index = 0\n",
        "        for items in test_loader:\n",
        "            name = self.test_dataset.load_name(index)\n",
        "            images, images_gray, edges, masks = self.cuda(*items)\n",
        "            index += 1\n",
        "\n",
        "            # edge model\n",
        "            if model == 1:\n",
        "                outputs = self.edge_model(images_gray, edges, masks)\n",
        "                outputs_merged = (outputs * masks) + (edges * (1 - masks))\n",
        "\n",
        "            # inpaint model\n",
        "            elif model == 2:\n",
        "                outputs = self.inpaint_model(images, edges, masks)\n",
        "                outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "            # inpaint with edge model / joint model\n",
        "            else:\n",
        "                edges = self.edge_model(images_gray, edges, masks).detach()\n",
        "                outputs = self.inpaint_model(images, edges, masks)\n",
        "                outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "            output = self.postprocess(outputs_merged)[0]\n",
        "            path = os.path.join(self.results_path, name)\n",
        "            print(index, name)\n",
        "\n",
        "            imsave(output, path)\n",
        "\n",
        "            if self.debug:\n",
        "                edges = self.postprocess(1 - edges)[0]\n",
        "                masked = self.postprocess(images * (1 - masks) + masks)[0]\n",
        "                fname, fext = name.split('.')\n",
        "\n",
        "                imsave(edges, os.path.join(self.results_path, fname + '_edge.' + fext))\n",
        "                imsave(masked, os.path.join(self.results_path, fname + '_masked.' + fext))\n",
        "\n",
        "        print('\\nEnd test....')\n",
        "\n",
        "    def sample(self, it=None):\n",
        "        # do not sample when validation set is empty\n",
        "        if len(self.val_dataset) == 0:\n",
        "            return\n",
        "\n",
        "        self.edge_model.eval()\n",
        "        self.inpaint_model.eval()\n",
        "\n",
        "        model = self.config.MODEL\n",
        "        items = next(self.sample_iterator)\n",
        "        images, images_gray, edges, masks = self.cuda(*items)\n",
        "\n",
        "        # edge model\n",
        "        if model == 1:\n",
        "            iteration = self.edge_model.iteration\n",
        "            inputs = (images_gray * (1 - masks)) + masks\n",
        "            outputs = self.edge_model(images_gray, edges, masks)\n",
        "            outputs_merged = (outputs * masks) + (edges * (1 - masks))\n",
        "\n",
        "        # inpaint model\n",
        "        elif model == 2:\n",
        "            iteration = self.inpaint_model.iteration\n",
        "            inputs = (images * (1 - masks)) + masks\n",
        "            outputs = self.inpaint_model(images, edges, masks)\n",
        "            outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "        # inpaint with edge model / joint model\n",
        "        else:\n",
        "            iteration = self.inpaint_model.iteration\n",
        "            inputs = (images * (1 - masks)) + masks\n",
        "            outputs = self.edge_model(images_gray, edges, masks).detach()\n",
        "            edges = (outputs * masks + edges * (1 - masks)).detach()\n",
        "            outputs = self.inpaint_model(images, edges, masks)\n",
        "            outputs_merged = (outputs * masks) + (images * (1 - masks))\n",
        "\n",
        "        if it is not None:\n",
        "            iteration = it\n",
        "\n",
        "        image_per_row = 2\n",
        "        if self.config.SAMPLE_SIZE <= 6:\n",
        "            image_per_row = 1\n",
        "\n",
        "        images = stitch_images(\n",
        "            self.postprocess(images),\n",
        "            self.postprocess(inputs),\n",
        "            self.postprocess(edges),\n",
        "            self.postprocess(outputs),\n",
        "            self.postprocess(outputs_merged),\n",
        "            img_per_row = image_per_row\n",
        "        )\n",
        "\n",
        "\n",
        "        path = os.path.join(self.samples_path, self.model_name)\n",
        "        name = os.path.join(path, str(iteration).zfill(5) + \".png\")\n",
        "        create_dir(path)\n",
        "        print('\\nsaving sample ' + name)\n",
        "        images.save(name)\n",
        "\n",
        "    def log(self, logs):\n",
        "        with open(self.log_file, 'a') as f:\n",
        "            f.write('%s\\n' % ' '.join([str(item[1]) for item in logs]))\n",
        "\n",
        "    def cuda(self, *args):\n",
        "        return (item.to(self.config.DEVICE) for item in args)\n",
        "\n",
        "    def postprocess(self, img):\n",
        "        # [0, 1] => [0, 255]\n",
        "        img = img * 255.0\n",
        "        img = img.permute(0, 2, 3, 1)\n",
        "        return img.int()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUxqJC30WlZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model\n",
        "%cd /content/edge-connect\n",
        "!python train.py --model 3 --checkpoints /content/training-checkpoints/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InsJhcpA6Bhc",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Test model\n",
        "%cd /content/edge-connect\n",
        "!python test.py \\\n",
        "  --model 3 \\\n",
        "  --checkpoints /content/training-checkpoints \\\n",
        "  --input /content/image.jpg \\\n",
        "  --mask /content/mask.png \\\n",
        "  --output /content/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
