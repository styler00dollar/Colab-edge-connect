{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-edge-connect.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEkV-m5FEJoM"
      },
      "source": [
        "# edge-connect with differentiable augmentation\n",
        "edge-connect: [knazeri/edge-connect](https://github.com/knazeri/edge-connect)\n",
        "\n",
        "Yukariins fork: [Yukariin/edge-connect](https://github.com/Yukariin/edge-connect)\n",
        "\n",
        "Differentiable Augmentation: [mit-han-lab/data-efficient-gans](https://github.com/mit-han-lab/data-efficient-gans)\n",
        "\n",
        "My fork: [styler00dollar/Colab-edge-connect](https://github.com/styler00dollar/Colab-edge-connect)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPLdOlecCkFa"
      },
      "source": [
        "# check gpu\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL5SvTn5BdBV",
        "cellView": "form"
      },
      "source": [
        "#@title Install\n",
        "%cd /content/\n",
        "!git clone https://github.com/styler00dollar/Colab-edge-connect\n",
        "!pip install numpy\n",
        "!pip install scipy==1.1\n",
        "!pip install future\n",
        "!pip install matplotlib\n",
        "!pip install pillow\n",
        "!pip install opencv-python\n",
        "!pip install scikit-image\n",
        "!pip install pyaml\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsHuihTpErN4"
      },
      "source": [
        "# Test with pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW0V5LkRB4ej",
        "cellView": "form"
      },
      "source": [
        "#@title Download models\n",
        "%cd /content/Colab-edge-connect\n",
        "!pip install gdown\n",
        "!mkdir checkpoint_places\n",
        "%cd checkpoint_places\n",
        "# /checkpoints broken\n",
        "# places\n",
        "!gdown --id 1gesVuuYMtlWSQRR2JE5eO0QZHskYRfqv\n",
        "!gdown --id 1_oYnmK7kppXqka9UUsHrZB4gWE4ouSgT\n",
        "!gdown --id 1M-r_ds4VZJnUqViDMofd4-Fy8-q2aeKJ\n",
        "!gdown --id 1G8lXquU3eREfs8KorFpFC8N4YmTQRksF\n",
        "%cd ..\n",
        "!mkdir checkpoint_celeba\n",
        "%cd checkpoint_celeba\n",
        "!gdown --id 1wy0pEaXTqmya2yeLwWFmTBf4ICexCdce\n",
        "!gdown --id 1hqZRjnqZBGnSTtGJRHXEvvdGVICUGa7u\n",
        "!gdown --id 17FemN4FAKpS5-8Dos582IrOiSCZNDOAO\n",
        "!gdown --id 15mH1ZHMf83q3woBHFELr_TptSRGc5g5j\n",
        "%cd ..\n",
        "!mkdir checkpoint_street\n",
        "%cd checkpoint_street\n",
        "!gdown --id 1ORF2uN4lB3F6YndPm1ny8VIDrsWQBwUS\n",
        "!gdown --id 1EwHK8YjcpO-X3xhmeo2dtqGvtY5vOMMj\n",
        "!gdown --id 1AWxB8AwTOrlOmAUho3IQQlmawtp3y8gZ\n",
        "!gdown --id 12Ua8oQwk0iLdYgrb08bqBhfyiBIumQEK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM4GOSz3CzJl",
        "cellView": "form"
      },
      "source": [
        "#@title dummy config\n",
        "%%writefile /content/Colab-edge-connect/config.yml\n",
        "MODE: 1             # 1: train, 2: test, 3: eval\n",
        "MODEL: 1            # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model\n",
        "MASK: 3             # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)\n",
        "EDGE: 1             # 1: canny, 2: external\n",
        "NMS: 1              # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny\n",
        "SEED: 10            # random seed\n",
        "GPU: [0]            # list of gpu ids\n",
        "DEBUG: 0            # turns on debugging mode\n",
        "VERBOSE: 0          # turns on verbose mode in the output console\n",
        "\n",
        "TRAIN_FLIST: ./datasets/places2_train.flist\n",
        "VAL_FLIST: ./datasets/places2_val.flist\n",
        "TEST_FLIST: ./datasets/places2_test.flist\n",
        "\n",
        "TRAIN_EDGE_FLIST: ./datasets/places2_edges_train.flist\n",
        "VAL_EDGE_FLIST: ./datasets/places2_edges_val.flist\n",
        "TEST_EDGE_FLIST: ./datasets/places2_edges_test.flist\n",
        "\n",
        "TRAIN_MASK_FLIST: ./datasets/masks_train.flist\n",
        "VAL_MASK_FLIST: ./datasets/masks_val.flist\n",
        "TEST_MASK_FLIST: ./datasets/masks_test.flist\n",
        "\n",
        "LR: 0.0001                    # learning rate\n",
        "D2G_LR: 0.1                   # discriminator/generator learning rate ratio\n",
        "BETA1: 0.0                    # adam optimizer beta1\n",
        "BETA2: 0.9                    # adam optimizer beta2\n",
        "BATCH_SIZE: 8                 # input batch size for training\n",
        "INPUT_SIZE: 256               # input image size for training 0 for original size\n",
        "SIGMA: 2                      # standard deviation of the Gaussian filter used in Canny edge detector (0: random, -1: no edge)\n",
        "MAX_ITERS: 2e6                # maximum number of iterations to train the model\n",
        "\n",
        "EDGE_THRESHOLD: 0.5           # edge detection threshold\n",
        "L1_LOSS_WEIGHT: 1             # l1 loss weight\n",
        "FM_LOSS_WEIGHT: 10            # feature-matching loss weight\n",
        "STYLE_LOSS_WEIGHT: 250        # style loss weight\n",
        "CONTENT_LOSS_WEIGHT: 0.1      # perceptual loss weight\n",
        "INPAINT_ADV_LOSS_WEIGHT: 0.1  # adversarial loss weight\n",
        "\n",
        "GAN_LOSS: nsgan               # nsgan | lsgan | hinge\n",
        "GAN_POOL_SIZE: 0              # fake images pool size\n",
        "\n",
        "SAVE_INTERVAL: 1000           # how many iterations to wait before saving model (0: never)\n",
        "SAMPLE_INTERVAL: 1000         # how many iterations to wait before sampling (0: never)\n",
        "SAMPLE_SIZE: 12               # number of images to sample\n",
        "EVAL_INTERVAL: 0              # how many iterations to wait before model evaluation (0: never)\n",
        "LOG_INTERVAL: 10              # how many iterations to wait before logging training status (0: never)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29t2_4dwGVPM"
      },
      "source": [
        "Currently default paths are ```/content/image.png``` and ```/content/mask.png```. Currently it's not supported that you change paths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgnGR9NAUqJg",
        "cellView": "form"
      },
      "source": [
        "#@title Image and mask need to be dividable by 4, this code does fix wrong images \n",
        "import cv2\n",
        "import numpy\n",
        "path_inpainting = '/content/image.png' #@param {type:\"string\"}\n",
        "path_mask = '/content/mask.png' #@param {type:\"string\"}\n",
        "image=cv2.imread(path_mask)\n",
        "image_size0 = numpy.floor(image.shape[0]/4)\n",
        "image_size1 = numpy.floor(image.shape[1]/4)\n",
        "image=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "ret,image=cv2.threshold(image,254,255,cv2.THRESH_BINARY)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_mask, image)\n",
        "\n",
        "image=cv2.imread(path_inpainting)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_inpainting, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4WHBATxfdl-",
        "cellView": "form"
      },
      "source": [
        "#@title print shape\n",
        "import cv2\n",
        "image = cv2.imread(path_inpainting)\n",
        "print(image.shape)\n",
        "image = cv2.imread(path_mask)\n",
        "print(image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuvHUtBwBri8",
        "cellView": "form"
      },
      "source": [
        "#@title Test Inpainting (result will be ```image.png```, the same filename you used as input)\n",
        "%cd /content/Colab-edge-connect\n",
        "!python test.py \\\n",
        "  --model 3 \\\n",
        "  --checkpoints /content/Colab-edge-connect/checkpoint_places \\\n",
        "  --input /content/image.png \\\n",
        "  --mask /content/mask.png \\\n",
        "  --output /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ard4kblETXdL"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hpN03bmG3Ja"
      },
      "source": [
        "Interesting stuff:\n",
        "- New pytorch versions won't work with the original code. This fork fixes it.\n",
        "- The ```.tflist``` simply lists filepaths for images.\n",
        "- It supports blocks as inpainting method, but random/custom masks need to be manually downloaded and input with a ```.tflist``` as well. Two example datasets are linked in the original github.\n",
        "- [Model 4 is not recommended](https://github.com/knazeri/edge-connect/issues/144). You should probably use model 3.\n",
        "- [Resuming and using a model as pretrained is being done by simply starting training while the models are in the specified checkpoint path.](https://github.com/knazeri/edge-connect/issues/54). Just make sure to use the default names. Further info in my fork README."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSPXmERCWpJ4",
        "cellView": "form"
      },
      "source": [
        "#@title Create empty folders\n",
        "!mkdir /content/training-checkpoints/\n",
        "!mkdir /content/train/\n",
        "!mkdir /content/val/\n",
        "!mkdir /content/mask_train/\n",
        "!mkdir /content/mask_val/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H--bAmNAJdms"
      },
      "source": [
        "Input all your data.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKhSZMdoH0WM",
        "cellView": "form"
      },
      "source": [
        "#@title modify paths inside prepare.py to create file list\n",
        "%%writefile /content/Colab-edge-connect/prepare.py\n",
        "#!/usr/bin/python\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "from random import shuffle\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--is_shuffled', default='1', type=int,\n",
        "                    help='Needed to shuffle')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    train_filename = 'train.flist'\n",
        "    validation_filename = 'val.flist'\n",
        "\n",
        "    train_path = '/home/path/'\n",
        "    val_path = '/home/path/'\n",
        "\n",
        "    training_file_names = []\n",
        "    validation_file_names = []\n",
        "\n",
        "    training_folder = os.listdir(train_path)\n",
        "\n",
        "    for training_item in training_folder:\n",
        "        training_item = train_path + \"/\" + training_item\n",
        "        training_file_names.append(training_item)\n",
        "\n",
        "    validation_folder = os.listdir(val_path)\n",
        "\n",
        "    for validation_item in validation_folder:\n",
        "        validation_item = val_path + \"/\" + validation_item\n",
        "        validation_file_names.append(validation_item)\n",
        "\n",
        "    # print all file paths\n",
        "    for i in training_file_names:\n",
        "        print(i)\n",
        "    for i in validation_file_names:\n",
        "        print(i)\n",
        "\n",
        "    # This would print all the files and directories\n",
        "\n",
        "    # shuffle file names if set\n",
        "    if args.is_shuffled == 1:\n",
        "        shuffle(training_file_names)\n",
        "        shuffle(validation_file_names)\n",
        "\n",
        "    # make output file if not existed\n",
        "    if not os.path.exists(train_filename):\n",
        "        os.mknod(train_filename)\n",
        "\n",
        "    if not os.path.exists(validation_filename):\n",
        "        os.mknod(validation_filename)\n",
        "\n",
        "    # write to file\n",
        "    fo = open(train_filename, \"w\")\n",
        "    fo.write(\"\\n\".join(training_file_names))\n",
        "    fo.close()\n",
        "\n",
        "    fo = open(validation_filename, \"w\")\n",
        "    fo.write(\"\\n\".join(validation_file_names))\n",
        "    fo.close()\n",
        "\n",
        "    # print process\n",
        "    print(\"Written file is: \", train_filename, \", is_shuffle: \", args.is_shuffled)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkRkDL9zH9NY",
        "cellView": "form"
      },
      "source": [
        "#@title create file list\n",
        "%cd /content/Colab-edge-connect\n",
        "!python prepare.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tglKPF-IesFt",
        "cellView": "form"
      },
      "source": [
        "#@title Training config\n",
        "%%writefile /content/training-checkpoints/config.yml\n",
        "MODE: 1             # 1: train, 2: test, 3: eval\n",
        "MODEL: 3            # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model\n",
        "MASK: 5             # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)\n",
        "EDGE: 1             # 1: canny, 2: external\n",
        "NMS: 1              # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny\n",
        "SEED: 10            # random seed\n",
        "GPU: [0]            # list of gpu ids\n",
        "DEBUG: 0            # turns on debugging mode\n",
        "VERBOSE: 0          # turns on verbose mode in the output console\n",
        "RANDOM_CROP: 1      # instead of center crop, a random crop without resize will be perofrmed\n",
        "HORIZONTAL_FLIP: 1      # flip in all directions (currently not sure where and if is in the original code. I just added my flip.)\n",
        "HORIZONTAL_FLIP_RATIO: 0.5\n",
        "VERTICAL_FLIP: 1\n",
        "VERTICAL_FLIP_RATIO: 0.5\n",
        "MOSAIC_TEST: 0      # Currently experimental. Inputs randomly resized image, which is overlayed with mask to the generator. Preview images during training won't show the real inputs. Currently 256x256 hardcoded.\n",
        "USE_AMP: 0              # Mixed precision training. Currently experimental. Will show a lot of Nan/Inf errors, but it seems to train fine.\n",
        "\n",
        "BATCH_SIZE: 1                 # input batch size for training\n",
        "INPUT_SIZE: 128               # input image size for training 0 for original size\n",
        "\n",
        "# Original Default: ['Adversarial', 'Perceptual', 'Style', 'DEFAULT_L1', 'DEFAULT_GAN']\n",
        "GENERATOR_LOSS: ['Adversarial', 'Perceptual', 'Style', 'DEFAULT_L1', 'DEFAULT_GAN', 'HFEN'] # Options: ['Adversarial', 'Perceptual', 'Style', 'DEFAULT_L1', 'NEW_L1', 'DEFAULT_GAN', 'NEW_GAN', 'HFEN', 'TV', 'ElasticLoss', 'RelativeL1', 'L1CosineSim', 'ClipL1', 'FFT', 'OF', 'GP', 'CP', 'Contextual']\n",
        "\n",
        "# default loss\n",
        "INPAINT_ADV_LOSS_WEIGHT: 0.1  # adversarial loss weight\n",
        "CONTENT_LOSS_WEIGHT: 0.1      # perceptual loss weight\n",
        "STYLE_LOSS_WEIGHT: 250        # style loss weight\n",
        "L1_LOSS_WEIGHT: 1             # l1 loss weight\n",
        "\n",
        "DEFAULT_GAN_LOSS: nsgan       # nsgan | lsgan | hinge\n",
        "GAN_POOL_SIZE: 0              # fake images pool size\n",
        "\n",
        "# new loss functions (values not tested)\n",
        "NEW_GAN_WEIGHT: 5e-3\n",
        "NEW_GAN_LOSS: 'hinge'         #vanilla, lsgan, srpgan, nsgan, BCE, hinge, wgan-gp (Only hinge seems not to crash, added GAN does not seem to work properly. This option is not really recommended.)\n",
        "\n",
        "L1_WEIGHT: 0.01               # using new L1\n",
        "HFEN_WEIGHT: 0.1              # high frequency error norm (HFEN) weight\n",
        "TV_WEIGHT: 0.000001           # total variation loss weight\n",
        "ElasticLoss_WEIGHT: 0.01\n",
        "RelativeL1_WEIGHT: 0.01 \n",
        "L1CosineSim_WEIGHT: 0.01 \n",
        "ClipL1_WEIGHT: 0.01 \n",
        "FFT_WEIGHT: 0.01 \n",
        "OF_WEIGHT: 0.01               # Overflow loss weight\n",
        "GP_WEIGHT: 0.01               # Gradient Profile (GP) loss weight\n",
        "CP_WEIGHT: 0.01               # Color Profile (CP) loss weight\n",
        "Contextual_WEIGHT: 10.01 \n",
        "HFEN_TYPE: 'Charbonnier' #L1, MSE, CharbonnierLoss(), Elastic, Relative, L1Cosine\n",
        "\n",
        "\n",
        "TRAIN_FLIST: /content/train/train.tflist\n",
        "VAL_FLIST: /content/val/val.tflist\n",
        "TEST_FLIST: /content/val/val.tflist\n",
        "\n",
        "TRAIN_EDGE_FLIST: NULL\n",
        "VAL_EDGE_FLIST: NULL\n",
        "TEST_EDGE_FLIST: NULL\n",
        "\n",
        "TRAIN_MASK_FLIST: /content/mask_train/mask_train.tflist\n",
        "VAL_MASK_FLIST: /content/mask_val/mask_val.tflist\n",
        "TEST_MASK_FLIST: /content/mask_val/mask_val.tflist\n",
        "\n",
        "LR: 0.0001                    # learning rate\n",
        "D2G_LR: 0.1                   # discriminator/generator learning rate ratio\n",
        "BETA1: 0.0                    # adam optimizer beta1\n",
        "BETA2: 0.9                    # adam optimizer beta2\n",
        "SIGMA: 2                      # standard deviation of the Gaussian filter used in Canny edge detector (0: random, -1: no edge)\n",
        "MAX_ITERS: 1000000                # maximum number of iterations to train the model\n",
        "\n",
        "EDGE_THRESHOLD: 0.5           # edge detection threshold\n",
        "FM_LOSS_WEIGHT: 10            # feature-matching loss weight (used in EdgeModel)\n",
        "\n",
        "\n",
        "# saving\n",
        "SAVE_INTERVAL: 5000           # how many iterations to wait before saving model (0: never)\n",
        "SAMPLE_INTERVAL: 100         # how many iterations to wait before sampling (0: never)\n",
        "SAMPLE_SIZE: 1               # number of images to sample\n",
        "EVAL_INTERVAL: 0              # how many iterations to wait before model evaluation (0: never)\n",
        "LOG_INTERVAL: 10              # how many iterations to wait before logging training status (0: never)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUxqJC30WlZW"
      },
      "source": [
        "# Train model\n",
        "%cd /content/Colab-edge-connect\n",
        "!python train.py --model 3 --checkpoints /content/training-checkpoints/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFaRu1BLcJah"
      },
      "source": [
        "- This will overwrite your original ```image.png```\n",
        "- Make sure the dimension is dividable by 4.\n",
        "- The default filenames for models are ```InpaintingModel_dis.pth``` and ```InpaintingModel_gen.pth```. Other names will be ignored.\n",
        "- You may or may not need to flip the image. The needed code is below.\n",
        "- ```image.png``` will be overwritten."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKarRtcpc3CY",
        "cellView": "form"
      },
      "source": [
        "#@title Image and mask need to be dividable by 4, this code does fix wrong images \n",
        "import cv2\n",
        "import numpy\n",
        "path_inpainting = '/content/image.png' #@param {type:\"string\"}\n",
        "path_mask = '/content/mask.png' #@param {type:\"string\"}\n",
        "image=cv2.imread(path_mask)\n",
        "image_size0 = numpy.floor(image.shape[0]/4)\n",
        "image_size1 = numpy.floor(image.shape[1]/4)\n",
        "image=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "ret,image=cv2.threshold(image,254,255,cv2.THRESH_BINARY)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_mask, image)\n",
        "\n",
        "image=cv2.imread(path_inpainting)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_inpainting, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7Xshcidb0rr",
        "cellView": "form"
      },
      "source": [
        "#@title Flip image\n",
        "import cv2\n",
        "filename = '/content/image.png' #@param {type:\"string\"}\n",
        "image = cv2.imread(filename)\n",
        "image = cv2.flip(image, 1)\n",
        "cv2.imwrite(filename, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InsJhcpA6Bhc",
        "cellView": "form"
      },
      "source": [
        "#@title Test model\n",
        "%cd /content/Colab-edge-connect\n",
        "checkpoints = '/content/training-checkpoints/' #@param {type:\"string\"}\n",
        "input = '/content/image.png' #@param {type:\"string\"}\n",
        "mask = '/content/mask.png' #@param {type:\"string\"}\n",
        "output = '/content/' #@param {type:\"string\"}\n",
        "!python test.py \\\n",
        "  --model 3 \\\n",
        "  --checkpoints {checkpoints} \\\n",
        "  --input {input} \\\n",
        "  --mask {mask} \\\n",
        "  --output {output}"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
