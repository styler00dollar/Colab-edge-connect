{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-edge-connect.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEkV-m5FEJoM",
        "colab_type": "text"
      },
      "source": [
        "# edge-connect with differentiable augmentation\n",
        "edge-connect: [knazeri/edge-connect](https://github.com/knazeri/edge-connect)\n",
        "\n",
        "Yukariins fork: [Yukariin/edge-connect](https://github.com/Yukariin/edge-connect)\n",
        "\n",
        "Differentiable Augmentation: [mit-han-lab/data-efficient-gans](https://github.com/mit-han-lab/data-efficient-gans)\n",
        "\n",
        "My fork: [styler00dollar/Colab-edge-connect](https://github.com/styler00dollar/Colab-edge-connect)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPLdOlecCkFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check gpu\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SL5SvTn5BdBV",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install\n",
        "!git clone https://github.com/styler00dollar/Colab-edge-connect\n",
        "%cd Colab-edge-connect\n",
        "!pip install -r requirements.txt\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsHuihTpErN4",
        "colab_type": "text"
      },
      "source": [
        "# Test with pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW0V5LkRB4ej",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Download models\n",
        "%cd /content/Colab-edge-connect\n",
        "!pip install gdown\n",
        "!mkdir checkpoint_places\n",
        "%cd checkpoint_places\n",
        "# /checkpoints broken\n",
        "# places\n",
        "!gdown --id 1gesVuuYMtlWSQRR2JE5eO0QZHskYRfqv\n",
        "!gdown --id 1_oYnmK7kppXqka9UUsHrZB4gWE4ouSgT\n",
        "!gdown --id 1M-r_ds4VZJnUqViDMofd4-Fy8-q2aeKJ\n",
        "!gdown --id 1G8lXquU3eREfs8KorFpFC8N4YmTQRksF\n",
        "%cd ..\n",
        "!mkdir checkpoint_celeba\n",
        "%cd checkpoint_celeba\n",
        "!gdown --id 1wy0pEaXTqmya2yeLwWFmTBf4ICexCdce\n",
        "!gdown --id 1hqZRjnqZBGnSTtGJRHXEvvdGVICUGa7u\n",
        "!gdown --id 17FemN4FAKpS5-8Dos582IrOiSCZNDOAO\n",
        "!gdown --id 15mH1ZHMf83q3woBHFELr_TptSRGc5g5j\n",
        "%cd ..\n",
        "!mkdir checkpoint_street\n",
        "%cd checkpoint_street\n",
        "!gdown --id 1ORF2uN4lB3F6YndPm1ny8VIDrsWQBwUS\n",
        "!gdown --id 1EwHK8YjcpO-X3xhmeo2dtqGvtY5vOMMj\n",
        "!gdown --id 1AWxB8AwTOrlOmAUho3IQQlmawtp3y8gZ\n",
        "!gdown --id 12Ua8oQwk0iLdYgrb08bqBhfyiBIumQEK"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM4GOSz3CzJl",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title dummy config\n",
        "%%writefile /content/Colab-edge-connect/config.yml\n",
        "MODE: 1             # 1: train, 2: test, 3: eval\n",
        "MODEL: 1            # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model\n",
        "MASK: 3             # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)\n",
        "EDGE: 1             # 1: canny, 2: external\n",
        "NMS: 1              # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny\n",
        "SEED: 10            # random seed\n",
        "GPU: [0]            # list of gpu ids\n",
        "DEBUG: 0            # turns on debugging mode\n",
        "VERBOSE: 0          # turns on verbose mode in the output console\n",
        "\n",
        "TRAIN_FLIST: ./datasets/places2_train.flist\n",
        "VAL_FLIST: ./datasets/places2_val.flist\n",
        "TEST_FLIST: ./datasets/places2_test.flist\n",
        "\n",
        "TRAIN_EDGE_FLIST: ./datasets/places2_edges_train.flist\n",
        "VAL_EDGE_FLIST: ./datasets/places2_edges_val.flist\n",
        "TEST_EDGE_FLIST: ./datasets/places2_edges_test.flist\n",
        "\n",
        "TRAIN_MASK_FLIST: ./datasets/masks_train.flist\n",
        "VAL_MASK_FLIST: ./datasets/masks_val.flist\n",
        "TEST_MASK_FLIST: ./datasets/masks_test.flist\n",
        "\n",
        "LR: 0.0001                    # learning rate\n",
        "D2G_LR: 0.1                   # discriminator/generator learning rate ratio\n",
        "BETA1: 0.0                    # adam optimizer beta1\n",
        "BETA2: 0.9                    # adam optimizer beta2\n",
        "BATCH_SIZE: 8                 # input batch size for training\n",
        "INPUT_SIZE: 256               # input image size for training 0 for original size\n",
        "SIGMA: 2                      # standard deviation of the Gaussian filter used in Canny edge detector (0: random, -1: no edge)\n",
        "MAX_ITERS: 2e6                # maximum number of iterations to train the model\n",
        "\n",
        "EDGE_THRESHOLD: 0.5           # edge detection threshold\n",
        "L1_LOSS_WEIGHT: 1             # l1 loss weight\n",
        "FM_LOSS_WEIGHT: 10            # feature-matching loss weight\n",
        "STYLE_LOSS_WEIGHT: 250        # style loss weight\n",
        "CONTENT_LOSS_WEIGHT: 0.1      # perceptual loss weight\n",
        "INPAINT_ADV_LOSS_WEIGHT: 0.1  # adversarial loss weight\n",
        "\n",
        "GAN_LOSS: nsgan               # nsgan | lsgan | hinge\n",
        "GAN_POOL_SIZE: 0              # fake images pool size\n",
        "\n",
        "SAVE_INTERVAL: 1000           # how many iterations to wait before saving model (0: never)\n",
        "SAMPLE_INTERVAL: 1000         # how many iterations to wait before sampling (0: never)\n",
        "SAMPLE_SIZE: 12               # number of images to sample\n",
        "EVAL_INTERVAL: 0              # how many iterations to wait before model evaluation (0: never)\n",
        "LOG_INTERVAL: 10              # how many iterations to wait before logging training status (0: never)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29t2_4dwGVPM",
        "colab_type": "text"
      },
      "source": [
        "Currently default paths are ```/content/image.png``` and ```/content/mask.png```. Currently it's not supported that you change paths."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgnGR9NAUqJg",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Image and mask need to be dividable by 4, this code does fix wrong images \n",
        "import cv2\n",
        "import numpy\n",
        "path_inpainting = '/content/image.png' #@param {type:\"string\"}\n",
        "path_mask = '/content/mask.png' #@param {type:\"string\"}\n",
        "image=cv2.imread(path_mask)\n",
        "image_size0 = numpy.floor(image.shape[0]/4)\n",
        "image_size1 = numpy.floor(image.shape[1]/4)\n",
        "image=cv2.cvtColor(image,cv2.COLOR_RGB2GRAY)\n",
        "ret,image=cv2.threshold(image,254,255,cv2.THRESH_BINARY)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_mask, image)\n",
        "\n",
        "image=cv2.imread(path_inpainting)\n",
        "image = cv2.resize(image, (int(image_size1*4), int(image_size0*4)), cv2.INTER_NEAREST)\n",
        "cv2.imwrite(path_inpainting, image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4WHBATxfdl-",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title print shape\n",
        "import cv2\n",
        "image = cv2.imread(path_inpainting)\n",
        "print(image.shape)\n",
        "image = cv2.imread(path_mask)\n",
        "print(image.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuvHUtBwBri8",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Test Inpainting (result will be ```image.png```, the same filename you used as input)\n",
        "%cd /content/Colab-edge-connect\n",
        "!python test.py \\\n",
        "  --model 3 \\\n",
        "  --checkpoints /content/Colab-edge-connect/checkpoint_places \\\n",
        "  --input /content/image.png \\\n",
        "  --mask /content/mask.png \\\n",
        "  --output /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ard4kblETXdL",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hpN03bmG3Ja",
        "colab_type": "text"
      },
      "source": [
        "Interesting stuff:\n",
        "- New pytorch versions won't work. Pytorch 1.0 makes problems. Pytorch 1.1 seems to work fine.\n",
        "- The ```.tflist``` simply lists filepaths for images.\n",
        "- It supports blocks as inpainting method, but random/custom masks need to be manually downloaded and input with a ```.tflist``` as well. Two example datasets are linked in the original github.\n",
        "- [Model 4 is not recommended](https://github.com/knazeri/edge-connect/issues/144). You should probably use model 3.\n",
        "- [Resuming and using a model as pretrained is being done by simply starting training while the models are in the specified checkpoint path.](https://github.com/knazeri/edge-connect/issues/54)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSPXmERCWpJ4",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create empty folders\n",
        "!mkdir /content/training-checkpoints/\n",
        "!mkdir /content/train/\n",
        "!mkdir /content/val/\n",
        "!mkdir /content/mask_train/\n",
        "!mkdir /content/mask_val/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H--bAmNAJdms",
        "colab_type": "text"
      },
      "source": [
        "Input all your data.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKhSZMdoH0WM",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title modify paths inside prepare.py to create file list\n",
        "%%writefile /content/Colab-edge-connect/prepare.py\n",
        "#!/usr/bin/python\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "from random import shuffle\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--is_shuffled', default='1', type=int,\n",
        "                    help='Needed to shuffle')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    train_filename = 'train.flist'\n",
        "    validation_filename = 'val.flist'\n",
        "\n",
        "    train_path = '/home/path/'\n",
        "    val_path = '/home/path/'\n",
        "\n",
        "    training_file_names = []\n",
        "    validation_file_names = []\n",
        "\n",
        "    training_folder = os.listdir(train_path)\n",
        "\n",
        "    for training_item in training_folder:\n",
        "        training_item = train_path + \"/\" + training_item\n",
        "        training_file_names.append(training_item)\n",
        "\n",
        "    validation_folder = os.listdir(val_path)\n",
        "\n",
        "    for validation_item in validation_folder:\n",
        "        validation_item = val_path + \"/\" + validation_item\n",
        "        validation_file_names.append(validation_item)\n",
        "\n",
        "    # print all file paths\n",
        "    for i in training_file_names:\n",
        "        print(i)\n",
        "    for i in validation_file_names:\n",
        "        print(i)\n",
        "\n",
        "    # This would print all the files and directories\n",
        "\n",
        "    # shuffle file names if set\n",
        "    if args.is_shuffled == 1:\n",
        "        shuffle(training_file_names)\n",
        "        shuffle(validation_file_names)\n",
        "\n",
        "    # make output file if not existed\n",
        "    if not os.path.exists(train_filename):\n",
        "        os.mknod(train_filename)\n",
        "\n",
        "    if not os.path.exists(validation_filename):\n",
        "        os.mknod(validation_filename)\n",
        "\n",
        "    # write to file\n",
        "    fo = open(train_filename, \"w\")\n",
        "    fo.write(\"\\n\".join(training_file_names))\n",
        "    fo.close()\n",
        "\n",
        "    fo = open(validation_filename, \"w\")\n",
        "    fo.write(\"\\n\".join(validation_file_names))\n",
        "    fo.close()\n",
        "\n",
        "    # print process\n",
        "    print(\"Written file is: \", train_filename, \", is_shuffle: \", args.is_shuffled)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkRkDL9zH9NY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create file list\n",
        "%cd /content/Colab-edge-connect\n",
        "!python prepare.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euuxf2YHlw7z",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install miniconda and dependencies\n",
        "%cd /content/\n",
        "!wget -c https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-4.5.4-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install pytorch==1.1 cudatoolkit torchvision -c pytorch -y\n",
        "%cd /content/Colab-edge-connect\n",
        "!pip install -r requirements.txt\n",
        "!conda install ipykernel -y\n",
        "!pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tglKPF-IesFt",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Training config\n",
        "%%writefile /content/training-checkpoints/config.yml\n",
        "MODE: 1             # 1: train, 2: test, 3: eval\n",
        "MODEL: 3            # 1: edge model, 2: inpaint model, 3: edge-inpaint model, 4: joint model\n",
        "MASK: 1             # 1: random block, 2: half, 3: external, 4: (external, random block), 5: (external, random block, half)\n",
        "EDGE: 1             # 1: canny, 2: external\n",
        "NMS: 1              # 0: no non-max-suppression, 1: applies non-max-suppression on the external edges by multiplying by Canny\n",
        "SEED: 10            # random seed\n",
        "GPU: [0]            # list of gpu ids\n",
        "DEBUG: 0            # turns on debugging mode\n",
        "VERBOSE: 0          # turns on verbose mode in the output console\n",
        "RANDOM_CROP: 1      # instead of center crop, a random crop without resize will be perofrmed\n",
        "HORIZONTAL_FLIP: 1      # flip in all directions (currently not sure where and if is in the original code. I just added my flip.)\n",
        "HORIZONTAL_FLIP_RATIO: 0.5\n",
        "VERTICAL_FLIP: 1\n",
        "VERTICAL_FLIP_RATIO: 0.5\n",
        "MOSAIC_TEST: 0      \n",
        "\n",
        "TRAIN_FLIST: /content/train/train.tflist\n",
        "VAL_FLIST: /content/val/val.tflist\n",
        "TEST_FLIST: /content/val/val.tflist\n",
        "\n",
        "TRAIN_EDGE_FLIST: NULL\n",
        "VAL_EDGE_FLIST: NULL\n",
        "TEST_EDGE_FLIST: NULL\n",
        "\n",
        "TRAIN_MASK_FLIST: /content/mask_train/mask_train.tflist\n",
        "VAL_MASK_FLIST: /content/mask_val/mask_val.tflist\n",
        "TEST_MASK_FLIST: /content/mask_val/mask_val.tflist\n",
        "\n",
        "LR: 0.0001                    # learning rate\n",
        "D2G_LR: 0.1                   # discriminator/generator learning rate ratio\n",
        "BETA1: 0.0                    # adam optimizer beta1\n",
        "BETA2: 0.9                    # adam optimizer beta2\n",
        "BATCH_SIZE: 6                 # input batch size for training\n",
        "INPUT_SIZE: 256               # input image size for training 0 for original size\n",
        "SIGMA: 2                      # standard deviation of the Gaussian filter used in Canny edge detector (0: random, -1: no edge)\n",
        "MAX_ITERS: 1000000                # maximum number of iterations to train the model\n",
        "\n",
        "EDGE_THRESHOLD: 0.5           # edge detection threshold\n",
        "L1_LOSS_WEIGHT: 1             # l1 loss weight\n",
        "FM_LOSS_WEIGHT: 10            # feature-matching loss weight\n",
        "STYLE_LOSS_WEIGHT: 250        # style loss weight\n",
        "CONTENT_LOSS_WEIGHT: 0.1      # perceptual loss weight\n",
        "INPAINT_ADV_LOSS_WEIGHT: 0.1  # adversarial loss weight\n",
        "\n",
        "GAN_LOSS: nsgan               # nsgan | lsgan | hinge\n",
        "GAN_POOL_SIZE: 0              # fake images pool size\n",
        "\n",
        "SAVE_INTERVAL: 200           # how many iterations to wait before saving model (0: never)\n",
        "SAMPLE_INTERVAL: 20         # how many iterations to wait before sampling (0: never)\n",
        "SAMPLE_SIZE: 1               # number of images to sample\n",
        "EVAL_INTERVAL: 0              # how many iterations to wait before model evaluation (0: never)\n",
        "LOG_INTERVAL: 10              # how many iterations to wait before logging training status (0: never)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUxqJC30WlZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model\n",
        "%cd /content/Colab-edge-connect\n",
        "!python train.py --model 3 --checkpoints /content/training-checkpoints/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InsJhcpA6Bhc",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Test model\n",
        "%cd /content/Colab-edge-connect\n",
        "!python test.py \\\n",
        "  --model 3 \\\n",
        "  --checkpoints /content/training-checkpoints \\\n",
        "  --input /content/image.jpg \\\n",
        "  --mask /content/mask.png \\\n",
        "  --output /content/"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
